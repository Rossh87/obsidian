(Some of the below is probablyspecific to passage-retreival style tasks, e.g. question answering)
Language model training generally consists of 3 phases:
1. Unsupervised language learning: In this phase, the model is offered enormous amounts of text data and tasked with performing word prediction. A single token of an excerpt is masked, and the model is penalized for incorrectly predicting what word should occur in the masked position. In this way the model 'learns' the token that is most likely to occur in a given position and context. Essentially the model is taught the meanings of words. This the most computationally expensive training phase, and requires huge amounts of input data.
2. Supervised, task-specific training: The model uses its general knowledge of language from the previous step to train for a specific task using a labelled dataset. Less training is required than for step 1, but it can be difficult to get enough labelled data. It is common to use large, publicly-available labelled datasets for teaching and benchmarking this task. MS Marco is an example of such a dataset that was created for the task of passage retrieval.
3. An optional domain adaptation phase: Specialization may require another round of training. For example, a model trained for passage retrieval may require extra training to perform acceptably in a specifc domain, for example medical texts. It can be difficult and expensive to assemble the domain-specific dataset needed for this training, as subject-matter experts are usually needed.

Fine-tuning can make models better at in-domain tasks than non ML-based methods (e.g. dense vector search vs. lexical search), but can also degrade the model's out-of-domain performance, which is a risk if the subject matter of the corpus may shift over time.

It is important to benchmark models against data other than the set used to train them. Shared, multi-domain datasets for certain tasks are one way to do this. The [BEIR](https://github.com/beir-cellar/beir)is a common heterogeneous dataset for benchmarking models trained for information retrieval tasks.