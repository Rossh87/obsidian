# Similarity Search

Since [[Vectors (embeddings)]] are mathematical representations of a phenomenon or piece of data (e.g. a chunk of text), vector search is simply identifying which of a set of existing vectors is most mathematically similar, or 'closest', to an input vector. The input vector can be thought of as the search term, and nearby vectors as the search results.

Different equations ('similarity metrics') are used to calculate vector closeness based on the intent of the search. In most cases, the best similarity metric is the same one used by the model that generated the embedding vectors.

## Metrics
- Euclidean distance:
	- Usually not used with embeddings generated by deep learning models, but useful with simpler vector encoding methods
	- Sensitive to scale: vectors with large values will be relatively more distant from vectors with small values, even if the vectors are otherwise similar
	- Euclidean distance is a composite of the distance between the 2 values at each dimension of the vectors under comparison, so a short Euclidean distance means each value in the two vectors is almost the same. This is not true of dot product or cosine.
- Dot product:
	- Calculated as the sum of the products of each element of the 2 vectors under comparison, e.g. `a1b1 + a2b2 + ... anbn`.
	- The sign and size of the resulting value indicate the relative angle between the two vectors as well as their relative magnitudes, which is taken as a measure of similarity.
	- IS affected by differences of magnitude
- Cosine similarity
	- Calculated by taking the dot product and dividing it by the product of their magnitudes
	- Is NOT affected by differences of magnitude, only accounts for the angle between the two vectors. 
	- If vectors are exactly the same direction, value is 1. If vectors are orthogonal, value is 0. If they are opposite, value is -1.
	- If the magnitude of some features are important in determining whether 2 values should be considered 'similar', cosine similarity is not appropriate. e.g. image embeddings of pixel intensities would not be appropriate for comparison with cosine similarity b/c the magnitude of individual pixels strongly influences whether 2 images are similar.

## Max Marginal Relevance
This technique builds on similarity metrics to rank results in a way that prioritizes diversity as well as similarity. In concrete terms, if two results are very similar to the search query, an MMR strategy might de-prioritize one of the results in favor of another result that is slightly less similar in order to promote diversity within the result set. The balance of similarity vs diversity is an input parameter to the MMR equation, usually a value between 0 and 1.